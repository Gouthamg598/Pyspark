{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5d7cdae-5127-46f9-b804-258fab3abd64",
   "metadata": {},
   "source": [
    "# What is DataFrame\n",
    "\n",
    "API Documentation: https://spark.apache.org/docs/3.5.0/api/python/reference/pyspark.sql/api/pyspark.sql.DataFrame.html\n",
    "https://spark.apache.org/docs/3.5.0/api/python/reference/pyspark.sql/dataframe.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ab2c2a9-7758-4d4d-9a86-619e25a7322f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "                    .master(\"local[*]\") \\\n",
    "                    .appName(\"Create Dataframe\") \\\n",
    "                    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "abd7bbd9-efb2-4ad4-8ce0-ebeee4dc9264",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://d5775686e5e4:4045\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.3</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Create Dataframe</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f9a2da5ca00>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b6a22a-c597-4738-a5f5-40042028451b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "spark.sparkContext.defaultParallelism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5231afeb-922c-4c11-8e33-ecea22828e2c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType\n",
    "customer_data = [\n",
    "    [\"C1\",\"Pratap\",\"16-12-1979\",10000],\n",
    "    [\"C2\",\"Sruthi\",\"08-01-1984\",20000],\n",
    "    [\"C3\",\"Kiyanshita\",\"24-08-2011\",30000],\n",
    "    [\"C4\",\"Nirupama\",\"01-11-2022\",40000]\n",
    "]\n",
    "\n",
    "customer_schema = StructType(fields = [\n",
    "                            StructField(name=\"CustomerID\", dataType=StringType(), nullable=True),\n",
    "                            StructField(name=\"CustomerName\", dataType=StringType(), nullable=True),\n",
    "                            StructField(name=\"CustomerDoB\", dataType=StringType(), nullable=True),\n",
    "                            StructField(name=\"CustomerSalary\", dataType=IntegerType(), nullable=True)\n",
    "                                    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9647546a-790d-4304-83b4-d106965b308c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = spark.createDataFrame(data=customer_data, schema=customer_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d73714ee-dc9a-4a44-bf30-ce6a3e52a9d3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- CustomerID: string (nullable = true)\n",
      " |-- CustomerName: string (nullable = true)\n",
      " |-- CustomerDoB: string (nullable = true)\n",
      " |-- CustomerSalary: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "19f55297-7f4a-4e58-9ce3-95b375059b71",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+-----------+--------------+\n",
      "|CustomerID|CustomerName|CustomerDoB|CustomerSalary|\n",
      "+----------+------------+-----------+--------------+\n",
      "|        C1|      Pratap| 16-12-1979|         10000|\n",
      "|        C2|      Sruthi| 08-01-1984|         20000|\n",
      "|        C3|  Kiyanshita| 24-08-2011|         30000|\n",
      "|        C4|    Nirupama| 01-11-2022|         40000|\n",
      "+----------+------------+-----------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1191caf9-f098-455b-baab-0cc5058363c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "    (\"James\",\"\",\"Smith\",\"36636\",\"M\",3000),\n",
    "    (\"Michael\",\"Rose\",\"\",\"40288\",\"M\",4000),\n",
    "    (\"Robert\",\"\",\"Williams\",\"42114\",\"M\",4000),\n",
    "    (\"Maria\",\"Anne\",\"Jones\",\"39192\",\"F\",4000),\n",
    "    (\"Jen\",\"Mary\",\"Brown\",\"\",\"F\",-1)\n",
    "  ]\n",
    "\n",
    "schema = StructType([ \\\n",
    "    StructField(\"firstname\",StringType(),True), \\\n",
    "    StructField(\"middlename\",StringType(),True), \\\n",
    "    StructField(\"lastname\",StringType(),True), \\\n",
    "    StructField(\"id\", StringType(), True), \\\n",
    "    StructField(\"gender\", StringType(), True), \\\n",
    "    StructField(\"salary\", IntegerType(), True) \\\n",
    "  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ade06db5-62bb-4afa-a9e6-33e770c5f96a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = spark.createDataFrame(data=data,schema=schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1f7a4ed-5d73-47cf-bdaf-fe859de1c2e5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- firstname: string (nullable = true)\n",
      " |-- middlename: string (nullable = true)\n",
      " |-- lastname: string (nullable = true)\n",
      " |-- id: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- salary: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eee4e249-5544-4e0e-88d6-14332198c7d3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+--------+-----+------+------+\n",
      "|firstname|middlename|lastname|   id|gender|salary|\n",
      "+---------+----------+--------+-----+------+------+\n",
      "|    James|          |   Smith|36636|     M|  3000|\n",
      "|  Michael|      Rose|        |40288|     M|  4000|\n",
      "|   Robert|          |Williams|42114|     M|  4000|\n",
      "|    Maria|      Anne|   Jones|39192|     F|  4000|\n",
      "|      Jen|      Mary|   Brown|     |     F|    -1|\n",
      "+---------+----------+--------+-----+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "621019a8-7bbd-4291-9026-001f224e86f4",
   "metadata": {},
   "source": [
    "## Defining Nested StructType object struct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5fb9f4fe-3cb2-45dc-bd7d-55e9269c3c17",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType\n",
    "\n",
    "structureData = [\n",
    "    ((\"James\",\"\",\"Smith\"),\"36636\",\"M\",3100),\n",
    "    ((\"Michael\",\"Rose\",\"\"),\"40288\",\"M\",4300),\n",
    "    ((\"Robert\",\"\",\"Williams\"),\"42114\",\"M\",1400),\n",
    "    ((\"Maria\",\"Anne\",\"Jones\"),\"39192\",\"F\",5500),\n",
    "    ((\"Jen\",\"Mary\",\"Brown\"),\"\",\"F\",-1)\n",
    "  ]\n",
    "\n",
    "customer_name_stuct = StructType( fields =[\n",
    "             StructField('firstname', StringType(), True),\n",
    "             StructField('middlename', StringType(), True),\n",
    "             StructField('lastname', StringType(), True)\n",
    "             ] )\n",
    "structureSchema = StructType( fields = [\n",
    "        StructField('name', customer_name_stuct, True),\n",
    "         StructField('id', StringType(), True),\n",
    "         StructField('gender', StringType(), True),\n",
    "         StructField('salary', IntegerType(), True)\n",
    "         ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a78dcf6d-e792-44a8-8acb-9d1bff252a01",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df2 = spark.createDataFrame(data=structureData,schema=structureSchema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "02004170-392a-4c2c-b876-faee99593334",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: struct (nullable = true)\n",
      " |    |-- firstname: string (nullable = true)\n",
      " |    |-- middlename: string (nullable = true)\n",
      " |    |-- lastname: string (nullable = true)\n",
      " |-- id: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- salary: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.printSchema()\n",
    "# df2.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e78137d0-7142-4edf-850f-d0135280361f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-------------+-----+\n",
      "|name.firstname|name.lastname|   id|\n",
      "+--------------+-------------+-----+\n",
      "|         James|        Smith|36636|\n",
      "|       Michael|             |40288|\n",
      "|        Robert|     Williams|42114|\n",
      "|         Maria|        Jones|39192|\n",
      "|           Jen|        Brown|     |\n",
      "+--------------+-------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "df2.select(df2.name[\"firstname\"],df2.name[\"lastname\"],df2[1] ).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "caf1f193-242c-4c44-b0a5-4e7870c20496",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+-------------------------------+----------+\n",
      "|name   |hobbies             |attributes                     |dob       |\n",
      "+-------+--------------------+-------------------------------+----------+\n",
      "|Alice  |[reading, cycling]  |{weight -> 55kg, height -> 5.6}|1990-01-01|\n",
      "|Bob    |[swimming, gaming]  |{weight -> 70kg, height -> 5.8}|1985-05-15|\n",
      "|Charlie|[hiking, travelling]|{weight -> 80kg, height -> 6.0}|1992-08-25|\n",
      "+-------+--------------------+-------------------------------+----------+\n",
      "\n",
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- hobbies: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- attributes: map (nullable = true)\n",
      " |    |-- key: string\n",
      " |    |-- value: string (valueContainsNull = true)\n",
      " |-- dob: date (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pyspark.sql.types import StructType, StructField, StringType, ArrayType, MapType, DateType\n",
    "# from pyspark.sql.functions import lit\n",
    "import datetime\n",
    "\n",
    "# Create SparkSession\n",
    "spark = SparkSession.builder.appName(\"ComplexDataTypesExample\").getOrCreate()\n",
    "\n",
    "# Define schema\n",
    "schema = StructType([\n",
    "    StructField(\"name\", StringType(), True),\n",
    "    StructField(\"hobbies\", ArrayType(StringType()), True),  # Array Type\n",
    "    StructField(\"attributes\", MapType(StringType(), StringType()), True),  # Map Type\n",
    "    StructField(\"dob\", DateType(), True)  # Date Type\n",
    "])\n",
    "\n",
    "# Sample data\n",
    "data = [\n",
    "    (\"Alice\", [\"reading\", \"cycling\"], {\"height\": \"5.6\", \"weight\": \"55kg\"}, datetime.date(1990, 1, 1)),\n",
    "    (\"Bob\", [\"swimming\", \"gaming\"], {\"height\": \"5.8\", \"weight\": \"70kg\"}, datetime.date(1985, 5, 15)),\n",
    "    (\"Charlie\", [\"hiking\", \"travelling\"], {\"height\": \"6.0\", \"weight\": \"80kg\"}, datetime.date(1992, 8, 25))\n",
    "]\n",
    "\n",
    "# Create DataFrame\n",
    "df = spark.createDataFrame(data, schema)\n",
    "\n",
    "# Show DataFrame\n",
    "df.show(truncate=False)\n",
    "\n",
    "# Print Schema\n",
    "df.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7eedfdb5-19ed-4d47-8e97-52639deafc9e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+-------------------------------+----------+------------------------+\n",
      "|name   |hobbies             |attributes                     |dob       |address                 |\n",
      "+-------+--------------------+-------------------------------+----------+------------------------+\n",
      "|Alice  |[reading, cycling]  |{weight -> 55kg, height -> 5.6}|1990-01-01|{New York, NY, 10001}   |\n",
      "|Bob    |[swimming, gaming]  |{weight -> 70kg, height -> 5.8}|1985-05-15|{Los Angeles, CA, 90001}|\n",
      "|Charlie|[hiking, travelling]|{weight -> 80kg, height -> 6.0}|1992-08-25|{Chicago, IL, 60601}    |\n",
      "+-------+--------------------+-------------------------------+----------+------------------------+\n",
      "\n",
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- hobbies: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- attributes: map (nullable = true)\n",
      " |    |-- key: string\n",
      " |    |-- value: string (valueContainsNull = true)\n",
      " |-- dob: date (nullable = true)\n",
      " |-- address: struct (nullable = true)\n",
      " |    |-- city: string (nullable = true)\n",
      " |    |-- state: string (nullable = true)\n",
      " |    |-- zip: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pyspark.sql.types import StructType, StructField, StringType, ArrayType, MapType, DateType\n",
    "\n",
    "import datetime\n",
    "\n",
    "# Create SparkSession\n",
    "spark = SparkSession.builder.appName(\"ComplexDataTypesWithNestedStruct\").getOrCreate()\n",
    "\n",
    "address_schema = StructType( fields = [  # Nested StructType\n",
    "        StructField(\"city\", StringType(), True),\n",
    "        StructField(\"state\", StringType(), True),\n",
    "        StructField(\"zip\", StringType(), True)\n",
    "    ])\n",
    "# Define schema\n",
    "schema = StructType([\n",
    "    StructField(\"name\", StringType(), True),\n",
    "    StructField(\"hobbies\", ArrayType(StringType()), True),  # Array Type\n",
    "    StructField(\"attributes\", MapType(StringType(), StringType()), True),  # Map Type\n",
    "    StructField(\"dob\", DateType(), True),  # Date Type\n",
    "    StructField(\"address\",address_schema , True)\n",
    "])\n",
    "\n",
    "# Sample data\n",
    "data = [\n",
    "    (\"Alice\", [\"reading\", \"cycling\"], {\"height\": \"5.6\", \"weight\": \"55kg\"}, datetime.date(1990, 1, 1), {\"city\": \"New York\", \"state\": \"NY\", \"zip\": \"10001\"}),\n",
    "    (\"Bob\", [\"swimming\", \"gaming\"], {\"height\": \"5.8\", \"weight\": \"70kg\"}, datetime.date(1985, 5, 15), {\"city\": \"Los Angeles\", \"state\": \"CA\", \"zip\": \"90001\"}),\n",
    "    (\"Charlie\", [\"hiking\", \"travelling\"], {\"height\": \"6.0\", \"weight\": \"80kg\"}, datetime.date(1992, 8, 25), {\"city\": \"Chicago\", \"state\": \"IL\", \"zip\": \"60601\"})\n",
    "]\n",
    "\n",
    "# Create DataFrame\n",
    "df = spark.createDataFrame(data, schema)\n",
    "\n",
    "# Show DataFrame\n",
    "df.show(truncate=False)\n",
    "\n",
    "# Print Schema\n",
    "df.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bf9f3834-24ab-4f78-84b0-c87a9548027a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column<'address'>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"address\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c9a40cf6-370e-4e6f-9cdc-af7e8c97d0ca",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column<'address'>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b2e6c753-63d4-47f4-acd0-91419b54588e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------+\n",
      "|address                 |\n",
      "+------------------------+\n",
      "|{New York, NY, 10001}   |\n",
      "|{Los Angeles, CA, 90001}|\n",
      "|{Chicago, IL, 60601}    |\n",
      "+------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(df.address).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5c25ef9f-e603-41c5-9478-53314efee149",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+-----------+-----+-----+----------+-------------+---------------+\n",
      "|name   |dob       |city       |state|zip  |hobby     |attribute_key|attribute_value|\n",
      "+-------+----------+-----------+-----+-----+----------+-------------+---------------+\n",
      "|Alice  |1990-01-01|New York   |NY   |10001|reading   |weight       |55kg           |\n",
      "|Alice  |1990-01-01|New York   |NY   |10001|reading   |height       |5.6            |\n",
      "|Alice  |1990-01-01|New York   |NY   |10001|cycling   |weight       |55kg           |\n",
      "|Alice  |1990-01-01|New York   |NY   |10001|cycling   |height       |5.6            |\n",
      "|Bob    |1985-05-15|Los Angeles|CA   |90001|swimming  |weight       |70kg           |\n",
      "|Bob    |1985-05-15|Los Angeles|CA   |90001|swimming  |height       |5.8            |\n",
      "|Bob    |1985-05-15|Los Angeles|CA   |90001|gaming    |weight       |70kg           |\n",
      "|Bob    |1985-05-15|Los Angeles|CA   |90001|gaming    |height       |5.8            |\n",
      "|Charlie|1992-08-25|Chicago    |IL   |60601|hiking    |weight       |80kg           |\n",
      "|Charlie|1992-08-25|Chicago    |IL   |60601|hiking    |height       |6.0            |\n",
      "|Charlie|1992-08-25|Chicago    |IL   |60601|travelling|weight       |80kg           |\n",
      "|Charlie|1992-08-25|Chicago    |IL   |60601|travelling|height       |6.0            |\n",
      "+-------+----------+-----------+-----+-----+----------+-------------+---------------+\n",
      "\n",
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- dob: date (nullable = true)\n",
      " |-- city: string (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- zip: string (nullable = true)\n",
      " |-- hobby: string (nullable = true)\n",
      " |-- attribute_key: string (nullable = true)\n",
      " |-- attribute_value: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, explode, lit, map_keys, map_values\n",
    "\n",
    "# Flattening StructType (Address fields)\n",
    "df_flattened = df.select(\n",
    "    col(\"name\"),\n",
    "    col(\"hobbies\"),\n",
    "    col(\"attributes\"),\n",
    "    col(\"dob\"),\n",
    "    col(\"address.city\").alias(\"city\"),\n",
    "    col(\"address.state\").alias(\"state\"),\n",
    "    col(\"address.zip\").alias(\"zip\")\n",
    ")\n",
    "\n",
    "# Exploding ArrayType (Hobbies)\n",
    "df_flattened = df_flattened.withColumn(\"hobby\", explode(col(\"hobbies\"))).drop(\"hobbies\")\n",
    "\n",
    "# Exploding MapType (Attributes)\n",
    "df_flattened = df_flattened.withColumn(\"attribute_key\", explode(map_keys(col(\"attributes\")))) \\\n",
    "                           .withColumn(\"attribute_value\", col(\"attributes\")[col(\"attribute_key\")]) \\\n",
    "                           .drop(\"attributes\")\n",
    "\n",
    "# Show the flattened DataFrame\n",
    "df_flattened.show(truncate=False)\n",
    "\n",
    "# Print Schema\n",
    "df_flattened.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca4d4d5-5ada-4b34-87e6-ff50f8683554",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
