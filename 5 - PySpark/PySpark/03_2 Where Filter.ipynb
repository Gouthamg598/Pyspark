{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5d7cdae-5127-46f9-b804-258fab3abd64",
   "metadata": {},
   "source": [
    "## Transformations\n",
    "\n",
    "    1. Select\n",
    "    2. expr, Col\n",
    "    3. SelectExpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ab2c2a9-7758-4d4d-9a86-619e25a7322f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "                    .master(\"local[*]\") \\\n",
    "                    .appName(\"Create Dataframe\") \\\n",
    "                    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "abd7bbd9-efb2-4ad4-8ce0-ebeee4dc9264",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b6a22a-c597-4738-a5f5-40042028451b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "spark.sparkContext.defaultParallelism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5231afeb-922c-4c11-8e33-ecea22828e2c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sales_data = [\n",
    "['SO101', '08-01-2024', 'Amit Joshi', 'Hyderabad', 'India', 'Keyboard', 3000, 4, 'pieces', 12000, 'INR', '18-01-2024'],\n",
    "['SO102', '19-01-2024', 'Divya Reddy', 'Mumbai', 'India', 'Printer', 1500, 5, 'pieces', 7500, 'INR', '29-01-2024'],\n",
    "['SO103', '01-01-2024', 'Rohan Patel', 'Pune', 'India', 'Laptop', 1500, 10, 'pieces', 15000, 'INR', '11-01-2024'],\n",
    "['SO104', '30-03-2024', 'Divya Reddy', 'Pune', 'India', 'External Hard Drive', 10000, 8, 'pieces', 80000, 'INR', '09-04-2024'],\n",
    "['SO105', '14-03-2024', 'Nikhil Desai', 'Ahmedabad', 'India', 'Wireless Mouse', 8000, 10, 'pieces', 80000, 'INR', '19-03-2024'],\n",
    "['SO106', '20-03-2024', 'Pooja Mehta', 'Hyderabad', 'India', 'Monitor', 8000, 10, 'pieces', 80000, 'INR', '25-03-2024'],\n",
    "['SO107', '10-03-2024', 'Amit Joshi', 'Mumbai', 'India', 'Webcam', 10000, 2, 'pieces', 20000, 'INR', '15-03-2024'],\n",
    "['SO108', '03-04-2024', 'Nikhil Desai', 'Pune', 'India', 'Wireless Mouse', 8000, 1, 'pieces', 8000, 'INR', '08-04-2024'],\n",
    "['SO109', '03-05-2024', 'Amit Joshi', 'Ahmedabad', 'India', 'Monitor', 70000, 5, 'pieces', 350000, 'INR', '18-05-2024'],\n",
    "['SO1010', '01-05-2024', 'Nikhil Desai', 'Ahmedabad', 'India', 'Monitor', 2000, 7, 'pieces', 14000, 'INR', '16-05-2024'],\n",
    "['SO1011', '19-06-2024', 'Amit Joshi', 'Chennai', 'India', 'Printer', 2000, 1, 'pieces', 2000, 'INR', '04-07-2024'],\n",
    "['SO1012', '08-07-2024', 'Rohan Patel', 'Mumbai', 'India', 'Keyboard', 3000, 5, 'pieces', 15000, 'INR', '23-07-2024'],\n",
    "['SO1013', '14-08-2024', 'Nikhil Desai', 'Mumbai', 'India', 'Keyboard', 10000, 10, 'pieces', 100000, 'INR', '29-08-2024'],\n",
    "['SO1014', '02-09-2024', 'Pooja Mehta', 'Ahmedabad', 'India', 'Laptop', 10000, 10, 'pieces', 100000, 'INR', '17-09-2024'],\n",
    "['SO1015', '23-09-2024', 'Amit Joshi', 'Chennai', 'India', 'Laptop', 8000, 6, 'pieces', 48000, 'INR', '08-10-2024'],\n",
    "['SO1016', '20-01-2023', 'Nikhil Desai', 'Ahmedabad', 'India', 'Webcam', 8000, 4, 'pieces', 32000, 'INR', '09-02-2023'],\n",
    "['SO1017', '01-01-2023', 'Nikhil Desai', 'Mumbai', 'India', 'Keyboard', 8000, 6, 'pieces', 48000, 'INR', '21-01-2023'],\n",
    "['SO1018', '26-01-2023', 'Nikhil Desai', 'Pune', 'India', 'Laptop', 10000, 5, 'pieces', 50000, 'INR', '15-02-2023'],\n",
    "['SO1019', '18-02-2023', 'Rohan Patel', 'Mumbai', 'India', 'Keyboard', 2000, 5, 'pieces', 10000, 'INR', '10-03-2023'],\n",
    "['SO1020', '24-03-2023', 'Amit Joshi', 'Pune', 'India', 'External Hard Drive', 5000, 5, 'pieces', 25000, 'INR', '13-04-2023'],\n",
    "['SO1021', '16-03-2023', 'Amit Joshi', 'Mumbai', 'India', 'Webcam', 10000, 7, 'pieces', 70000, 'INR', '10-04-2023'],\n",
    "['SO1022', '30-04-2023', 'Amit Joshi', 'Pune', 'India', 'Laptop', 70000, 5, 'pieces', 350000, 'INR', '25-05-2023'],\n",
    "['SO1023', '13-04-2023', 'Nikhil Desai', 'Mumbai', 'India', 'Wireless Mouse', 3000, 3, 'pieces', 9000, 'INR', '08-05-2023'],\n",
    "['SO1024', '08-07-2023', 'Pooja Mehta', 'Ahmedabad', 'India', 'Wireless Mouse', 5000, 2, 'pieces', 10000, 'INR', '02-08-2023'],\n",
    "['SO1025', '25-07-2023', 'Rohan Patel', 'Chennai', 'India', 'External Hard Drive', 5000, 7, 'pieces', 35000, 'INR', '19-08-2023'],\n",
    "['SO1026', '14-07-2023', 'Divya Reddy', 'Ahmedabad', 'India', 'Keyboard', 1500, 8, 'pieces', 12000, 'INR', '08-08-2023'],\n",
    "['SO1027', '24-07-2023', 'Rohan Patel', 'Hyderabad', 'India', 'Laptop', 3000, 9, 'pieces', 27000, 'INR', '18-08-2023'],\n",
    "['SO1028', '25-07-2023', 'Rohan Patel', 'Chennai', 'India', 'Monitor', 5000, 8, 'pieces', 40000, 'INR', '19-08-2023'],\n",
    "['SO1029', '17-09-2023', 'Divya Reddy', 'Chennai', 'India', 'Wireless Mouse', 1500, 8, 'pieces', 12000, 'INR', '12-10-2023'],\n",
    "['SO1030', '08-09-2023', 'Nikhil Desai', 'Chennai', 'India', 'Webcam', 8000, 9, 'pieces', 72000, 'INR', '03-10-2023']\n",
    "\n",
    "]\n",
    "\n",
    "sales_schema = \"\"\"SalesOrder string, \n",
    "                    OrderDate string, \n",
    "                    CustomerName string, \n",
    "                    City string, \n",
    "                    Country string, \n",
    "                    Product string, \n",
    "                    Price integer, \n",
    "                    Qty_Sold integer, \n",
    "                    Qty_Sold_Units string, \n",
    "                    Amount integer, \n",
    "                    Amount_Currency string, \n",
    "                    ShipDate string\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9647546a-790d-4304-83b4-d106965b308c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sales_df = spark.createDataFrame(data=sales_data, schema=sales_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d73714ee-dc9a-4a44-bf30-ce6a3e52a9d3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- SalesOrder: string (nullable = true)\n",
      " |-- OrderDate: string (nullable = true)\n",
      " |-- CustomerName: string (nullable = true)\n",
      " |-- City: string (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      " |-- Product: string (nullable = true)\n",
      " |-- Price: integer (nullable = true)\n",
      " |-- Qty_Sold: integer (nullable = true)\n",
      " |-- Qty_Sold_Units: string (nullable = true)\n",
      " |-- Amount: integer (nullable = true)\n",
      " |-- Amount_Currency: string (nullable = true)\n",
      " |-- ShipDate: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sales_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "19f55297-7f4a-4e58-9ce3-95b375059b71",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+------------+---------+-------+-------------------+-----+--------+--------------+------+---------------+----------+\n",
      "|SalesOrder| OrderDate|CustomerName|     City|Country|            Product|Price|Qty_Sold|Qty_Sold_Units|Amount|Amount_Currency|  ShipDate|\n",
      "+----------+----------+------------+---------+-------+-------------------+-----+--------+--------------+------+---------------+----------+\n",
      "|     SO101|08-01-2024|  Amit Joshi|Hyderabad|  India|           Keyboard| 3000|       4|        pieces| 12000|            INR|18-01-2024|\n",
      "|     SO102|19-01-2024| Divya Reddy|   Mumbai|  India|            Printer| 1500|       5|        pieces|  7500|            INR|29-01-2024|\n",
      "|     SO103|01-01-2024| Rohan Patel|     Pune|  India|             Laptop| 1500|      10|        pieces| 15000|            INR|11-01-2024|\n",
      "|     SO104|30-03-2024| Divya Reddy|     Pune|  India|External Hard Drive|10000|       8|        pieces| 80000|            INR|09-04-2024|\n",
      "|     SO105|14-03-2024|Nikhil Desai|Ahmedabad|  India|     Wireless Mouse| 8000|      10|        pieces| 80000|            INR|19-03-2024|\n",
      "|     SO106|20-03-2024| Pooja Mehta|Hyderabad|  India|            Monitor| 8000|      10|        pieces| 80000|            INR|25-03-2024|\n",
      "|     SO107|10-03-2024|  Amit Joshi|   Mumbai|  India|             Webcam|10000|       2|        pieces| 20000|            INR|15-03-2024|\n",
      "|     SO108|03-04-2024|Nikhil Desai|     Pune|  India|     Wireless Mouse| 8000|       1|        pieces|  8000|            INR|08-04-2024|\n",
      "|     SO109|03-05-2024|  Amit Joshi|Ahmedabad|  India|            Monitor|70000|       5|        pieces|350000|            INR|18-05-2024|\n",
      "|    SO1010|01-05-2024|Nikhil Desai|Ahmedabad|  India|            Monitor| 2000|       7|        pieces| 14000|            INR|16-05-2024|\n",
      "|    SO1011|19-06-2024|  Amit Joshi|  Chennai|  India|            Printer| 2000|       1|        pieces|  2000|            INR|04-07-2024|\n",
      "|    SO1012|08-07-2024| Rohan Patel|   Mumbai|  India|           Keyboard| 3000|       5|        pieces| 15000|            INR|23-07-2024|\n",
      "|    SO1013|14-08-2024|Nikhil Desai|   Mumbai|  India|           Keyboard|10000|      10|        pieces|100000|            INR|29-08-2024|\n",
      "|    SO1014|02-09-2024| Pooja Mehta|Ahmedabad|  India|             Laptop|10000|      10|        pieces|100000|            INR|17-09-2024|\n",
      "|    SO1015|23-09-2024|  Amit Joshi|  Chennai|  India|             Laptop| 8000|       6|        pieces| 48000|            INR|08-10-2024|\n",
      "|    SO1016|20-01-2023|Nikhil Desai|Ahmedabad|  India|             Webcam| 8000|       4|        pieces| 32000|            INR|09-02-2023|\n",
      "|    SO1017|01-01-2023|Nikhil Desai|   Mumbai|  India|           Keyboard| 8000|       6|        pieces| 48000|            INR|21-01-2023|\n",
      "|    SO1018|26-01-2023|Nikhil Desai|     Pune|  India|             Laptop|10000|       5|        pieces| 50000|            INR|15-02-2023|\n",
      "|    SO1019|18-02-2023| Rohan Patel|   Mumbai|  India|           Keyboard| 2000|       5|        pieces| 10000|            INR|10-03-2023|\n",
      "|    SO1020|24-03-2023|  Amit Joshi|     Pune|  India|External Hard Drive| 5000|       5|        pieces| 25000|            INR|13-04-2023|\n",
      "+----------+----------+------------+---------+-------+-------------------+-----+--------+--------------+------+---------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sales_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5579de9d-56b8-4c23-a5e2-76aefbd63609",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+\n",
      "|CustomerName|\n",
      "+------------+\n",
      "|  Amit Joshi|\n",
      "|  Amit Joshi|\n",
      "|  Amit Joshi|\n",
      "|  Amit Joshi|\n",
      "|  Amit Joshi|\n",
      "|  Amit Joshi|\n",
      "|  Amit Joshi|\n",
      "|  Amit Joshi|\n",
      "+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import expr\n",
    "sales_df.select(sales_df.CustomerName).where(expr(\"left(CustomerName,1)\") == 'A').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58838af6-5aae-45f6-880d-19820c8adc4c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+------------+---------+-------+-------+-----+--------+--------------+------+---------------+----------+\n",
      "|SalesOrder| OrderDate|CustomerName|     City|Country|Product|Price|Qty_Sold|Qty_Sold_Units|Amount|Amount_Currency|  ShipDate|\n",
      "+----------+----------+------------+---------+-------+-------+-----+--------+--------------+------+---------------+----------+\n",
      "|     SO109|03-05-2024|  Amit Joshi|Ahmedabad|  India|Monitor|70000|       5|        pieces|350000|            INR|18-05-2024|\n",
      "|    SO1022|30-04-2023|  Amit Joshi|     Pune|  India| Laptop|70000|       5|        pieces|350000|            INR|25-05-2023|\n",
      "+----------+----------+------------+---------+-------+-------+-----+--------+--------------+------+---------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Select * from sales_df where Amount > 100000\n",
    "\n",
    "\n",
    "sales_df.where(\"Amount > 100000\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "26b09105-45c4-41e5-8bc6-5d5b0eb235ae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+------------+---------+-------+-------+-----+--------+--------------+------+---------------+----------+\n",
      "|SalesOrder| OrderDate|CustomerName|     City|Country|Product|Price|Qty_Sold|Qty_Sold_Units|Amount|Amount_Currency|  ShipDate|\n",
      "+----------+----------+------------+---------+-------+-------+-----+--------+--------------+------+---------------+----------+\n",
      "|     SO109|03-05-2024|  Amit Joshi|Ahmedabad|  India|Monitor|70000|       5|        pieces|350000|            INR|18-05-2024|\n",
      "|    SO1022|30-04-2023|  Amit Joshi|     Pune|  India| Laptop|70000|       5|        pieces|350000|            INR|25-05-2023|\n",
      "+----------+----------+------------+---------+-------+-------+-----+--------+--------------+------+---------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "sales_df.where(col(\"Amount\") > 100000).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7ee09373-ca83-4d6e-bf0e-3b895162709e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+------------+---------+-------+-------+-----+--------+--------------+------+---------------+----------+\n",
      "|SalesOrder| OrderDate|CustomerName|     City|Country|Product|Price|Qty_Sold|Qty_Sold_Units|Amount|Amount_Currency|  ShipDate|\n",
      "+----------+----------+------------+---------+-------+-------+-----+--------+--------------+------+---------------+----------+\n",
      "|     SO109|03-05-2024|  Amit Joshi|Ahmedabad|  India|Monitor|70000|       5|        pieces|350000|            INR|18-05-2024|\n",
      "+----------+----------+------------+---------+-------+-------+-----+--------+--------------+------+---------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Select * from sales_df where Amount > 100000 and City = 'Ahmedabad'\n",
    "\n",
    "sales_df.where(\"Amount > 100000 and City = 'Ahmedabad'\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a636fc85-9e05-43be-a6b5-8011fe260371",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+------------+---------+-------+-------+-----+--------+--------------+------+---------------+----------+\n",
      "|SalesOrder| OrderDate|CustomerName|     City|Country|Product|Price|Qty_Sold|Qty_Sold_Units|Amount|Amount_Currency|  ShipDate|\n",
      "+----------+----------+------------+---------+-------+-------+-----+--------+--------------+------+---------------+----------+\n",
      "|     SO109|03-05-2024|  Amit Joshi|Ahmedabad|  India|Monitor|70000|       5|        pieces|350000|            INR|18-05-2024|\n",
      "+----------+----------+------------+---------+-------+-------+-----+--------+--------------+------+---------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Select * from sales_df where Amount > 100000 and City = 'Ahmedabad'\n",
    "\n",
    "sales_df.where((col(\"Amount\") > 100000) & (col(\"City\") == 'Ahmedabad')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aec0089d-e2e4-4a7b-9bbb-03b1075d16c5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+------------+---------+-------+-------+-----+--------+--------------+------+---------------+----------+\n",
      "|SalesOrder| OrderDate|CustomerName|     City|Country|Product|Price|Qty_Sold|Qty_Sold_Units|Amount|Amount_Currency|  ShipDate|\n",
      "+----------+----------+------------+---------+-------+-------+-----+--------+--------------+------+---------------+----------+\n",
      "|     SO109|03-05-2024|  Amit Joshi|Ahmedabad|  India|Monitor|70000|       5|        pieces|350000|            INR|18-05-2024|\n",
      "+----------+----------+------------+---------+-------+-------+-----+--------+--------------+------+---------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Select * from sales_df where Amount > 100000 and left(City,1) = 'A'\n",
    "sales_df.where(\"Amount > 100000 and left(City,1) = 'A'\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8f3c4b18-788b-4417-a599-b152b1f86d76",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "PySparkTypeError",
     "evalue": "[NOT_COLUMN_OR_STR] Argument `col` should be a Column or str, got int.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPySparkTypeError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m## Select * from sales_df where Amount > 100000 and left(City,1) = 'A'\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# from pyspark.sql.functions import left\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m sales_df\u001b[38;5;241m.\u001b[39mwhere( (\u001b[43mleft\u001b[49m\u001b[43m(\u001b[49m\u001b[43msales_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCity\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA\u001b[39m\u001b[38;5;124m'\u001b[39m))\u001b[38;5;241m.\u001b[39mshow()\n",
      "File \u001b[0;32m/spark/python/pyspark/sql/utils.py:174\u001b[0m, in \u001b[0;36mtry_remote_functions.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(functions, f\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 174\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/spark/python/pyspark/sql/functions.py:10914\u001b[0m, in \u001b[0;36mleft\u001b[0;34m(str, len)\u001b[0m\n\u001b[1;32m  10893\u001b[0m \u001b[38;5;129m@try_remote_functions\u001b[39m\n\u001b[1;32m  10894\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mleft\u001b[39m(\u001b[38;5;28mstr\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mColumnOrName\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mlen\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mColumnOrName\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Column:\n\u001b[1;32m  10895\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m  10896\u001b[0m \u001b[38;5;124;03m    Returns the leftmost `len`(`len` can be string type) characters from the string `str`,\u001b[39;00m\n\u001b[1;32m  10897\u001b[0m \u001b[38;5;124;03m    if `len` is less or equal than 0 the result is an empty string.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  10912\u001b[0m \u001b[38;5;124;03m    [Row(r='Spa')]\u001b[39;00m\n\u001b[1;32m  10913\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m> 10914\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_invoke_function_over_columns\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mleft\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/spark/python/pyspark/sql/functions.py:105\u001b[0m, in \u001b[0;36m_invoke_function_over_columns\u001b[0;34m(name, *cols)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_invoke_function_over_columns\u001b[39m(name: \u001b[38;5;28mstr\u001b[39m, \u001b[38;5;241m*\u001b[39mcols: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mColumnOrName\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Column:\n\u001b[1;32m    101\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;124;03m    Invokes n-ary JVM function identified by name\u001b[39;00m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;124;03m    and wraps the result with :class:`~pyspark.sql.Column`.\u001b[39;00m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 105\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _invoke_function(name, \u001b[38;5;241m*\u001b[39m(_to_java_column(col) \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m cols))\n",
      "File \u001b[0;32m/spark/python/pyspark/sql/functions.py:105\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_invoke_function_over_columns\u001b[39m(name: \u001b[38;5;28mstr\u001b[39m, \u001b[38;5;241m*\u001b[39mcols: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mColumnOrName\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Column:\n\u001b[1;32m    101\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;124;03m    Invokes n-ary JVM function identified by name\u001b[39;00m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;124;03m    and wraps the result with :class:`~pyspark.sql.Column`.\u001b[39;00m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 105\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _invoke_function(name, \u001b[38;5;241m*\u001b[39m(\u001b[43m_to_java_column\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m cols))\n",
      "File \u001b[0;32m/spark/python/pyspark/sql/column.py:65\u001b[0m, in \u001b[0;36m_to_java_column\u001b[0;34m(col)\u001b[0m\n\u001b[1;32m     63\u001b[0m     jcol \u001b[38;5;241m=\u001b[39m _create_column_from_name(col)\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PySparkTypeError(\n\u001b[1;32m     66\u001b[0m         error_class\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNOT_COLUMN_OR_STR\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     67\u001b[0m         message_parameters\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marg_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcol\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marg_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mtype\u001b[39m(col)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m},\n\u001b[1;32m     68\u001b[0m     )\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m jcol\n",
      "\u001b[0;31mPySparkTypeError\u001b[0m: [NOT_COLUMN_OR_STR] Argument `col` should be a Column or str, got int."
     ]
    }
   ],
   "source": [
    "## Select * from sales_df where Amount > 100000 and left(City,1) = 'A'\n",
    "# from pyspark.sql.functions import left\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a20966-7a90-4a92-b303-2c6fa43162d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
